{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMu7maN+m5yHxa6A1Nw/Wfc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boomyun713/114_homework/blob/main/W9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_9VPwDrQWXKW"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"第9週作業：智能特徵篩選 - 基因演算法 vs 模擬退火\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用設備: {device}\")\n",
        "\n",
        "OUTPUT_DIR = './outputs/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"輸出目錄: {OUTPUT_DIR}\\n\")\n",
        "\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.rcParams['figure.figsize'] = (14, 6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rY87-SfWjoF",
        "outputId": "133ec284-41ad-4953-8f34-c8b1e595e5bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "第9週作業：智能特徵篩選 - 基因演算法 vs 模擬退火\n",
            "================================================================================\n",
            "使用設備: cuda\n",
            "輸出目錄: ./outputs/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"[Part 1/6] 資料收集與特徵工程\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = \"AAPL\"\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "if isinstance(stock_data.columns, pd.MultiIndex):\n",
        "    stock_data.columns = stock_data.columns.get_level_values(0)\n",
        "\n",
        "print(f\"下載 {ticker} 資料：{start_date} 至 {end_date}\")\n",
        "print(f\"原始資料形狀：{stock_data.shape}\")\n",
        "\n",
        "print(\"\\n計算技術指標...\")\n",
        "\n",
        "stock_data['SMA_5'] = stock_data['Close'].rolling(window=5).mean()\n",
        "stock_data['SMA_10'] = stock_data['Close'].rolling(window=10).mean()\n",
        "stock_data['SMA_20'] = stock_data['Close'].rolling(window=20).mean()\n",
        "stock_data['EMA_12'] = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "stock_data['EMA_26'] = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "ema_12 = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "ema_26 = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "stock_data['MACD'] = ema_12 - ema_26\n",
        "stock_data['MACD_SIGNAL'] = stock_data['MACD'].ewm(span=9, adjust=False).mean()\n",
        "stock_data['MACD_HIST'] = stock_data['MACD'] - stock_data['MACD_SIGNAL']\n",
        "\n",
        "delta = stock_data['Close'].diff()\n",
        "gain = delta.mask(delta < 0, 0)\n",
        "loss = -delta.mask(delta > 0, 0)\n",
        "avg_gain = gain.ewm(com=13, min_periods=14).mean()\n",
        "avg_loss = loss.ewm(com=13, min_periods=14).mean()\n",
        "rs = avg_gain / avg_loss\n",
        "stock_data['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "low_14 = stock_data['Low'].rolling(window=14).min()\n",
        "high_14 = stock_data['High'].rolling(window=14).max()\n",
        "stock_data['STOCH_K'] = 100 * ((stock_data['Close'] - low_14) / (high_14 - low_14))\n",
        "stock_data['STOCH_D'] = stock_data['STOCH_K'].rolling(window=3).mean()\n",
        "\n",
        "stock_data['ROC'] = ((stock_data['Close'] - stock_data['Close'].shift(12)) /\n",
        "                     stock_data['Close'].shift(12)) * 100\n",
        "\n",
        "tp = (stock_data['High'] + stock_data['Low'] + stock_data['Close']) / 3.0\n",
        "sma_tp_20 = tp.rolling(20).mean()\n",
        "mean_dev_20 = (tp - sma_tp_20).abs().rolling(20).mean()\n",
        "stock_data['CCI_20'] = (tp - sma_tp_20) / (0.015 * (mean_dev_20 + 1e-8))\n",
        "\n",
        "bb_mid = stock_data['Close'].rolling(20).mean()\n",
        "if isinstance(bb_mid, pd.DataFrame): bb_mid = bb_mid.iloc[:, 0]\n",
        "bb_std = stock_data['Close'].rolling(20).std()\n",
        "if isinstance(bb_std, pd.DataFrame): bb_std = bb_std.iloc[:, 0]\n",
        "\n",
        "stock_data['BB_MID_20'] = bb_mid.astype(float)\n",
        "stock_data['BB_UP_20'] = (bb_mid + 2 * bb_std).astype(float)\n",
        "stock_data['BB_LOW_20'] = (bb_mid - 2 * bb_std).astype(float)\n",
        "bb_width_20 = (stock_data['BB_UP_20'] - stock_data['BB_LOW_20']) / (bb_mid + 1e-8)\n",
        "if isinstance(bb_width_20, pd.DataFrame): bb_width_20 = bb_width_20.iloc[:, 0]\n",
        "stock_data['BB_WIDTH_20'] = bb_width_20.astype(float)\n",
        "\n",
        "hl = stock_data['High'] - stock_data['Low']\n",
        "hc = (stock_data['High'] - stock_data['Close'].shift(1)).abs()\n",
        "lc = (stock_data['Low'] - stock_data['Close'].shift(1)).abs()\n",
        "tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)\n",
        "stock_data['ATR_14'] = tr.rolling(window=14, min_periods=14).mean()\n",
        "\n",
        "log_ret = np.log(stock_data['Close'] / stock_data['Close'].shift(1))\n",
        "stock_data['HV_30'] = log_ret.rolling(30).std() * np.sqrt(252)\n",
        "\n",
        "hl_range = (stock_data['High'] - stock_data['Low']).abs()\n",
        "ema_hl_10 = hl_range.ewm(span=10, adjust=False).mean()\n",
        "stock_data['ChaikinVol_10'] = 100.0 * (ema_hl_10 - ema_hl_10.shift(10)) / (ema_hl_10.shift(10) + 1e-8)\n",
        "\n",
        "price_diff = stock_data['Close'].diff()\n",
        "volume_direction = np.where(price_diff > 0, stock_data['Volume'],\n",
        "                            np.where(price_diff < 0, -stock_data['Volume'], 0))\n",
        "stock_data['OBV'] = volume_direction.cumsum()\n",
        "\n",
        "vwap_num = (tp * stock_data['Volume']).cumsum()\n",
        "vwap_den = stock_data['Volume'].cumsum()\n",
        "stock_data['VWAP'] = vwap_num / (vwap_den + 1e-8)\n",
        "\n",
        "vol_ma_s = stock_data['Volume'].rolling(14).mean()\n",
        "vol_ma_l = stock_data['Volume'].rolling(28).mean()\n",
        "stock_data['VolOsc'] = 100 * (vol_ma_s - vol_ma_l) / (vol_ma_l + 1e-8)\n",
        "\n",
        "stock_data['WEEKDAY_ENC'] = stock_data.index.dayofweek.astype(float) # 週幾 (0-6)\n",
        "stock_data['MONTH_ENC'] = stock_data.index.month.astype(float) # 月份 (1-12)\n",
        "\n",
        "stock_data['NOISE_VOL'] = stock_data['Volume'].astype(float) + np.random.randn(len(stock_data)) * 1000\n",
        "\n",
        "stock_data['Target'] = stock_data['Close'].shift(-1)\n",
        "stock_data = stock_data.dropna()\n",
        "\n",
        "ALL_FEATURES = [col for col in stock_data.columns if col not in\n",
        "                ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Target']]\n",
        "print(f\"總特徵數: {len(ALL_FEATURES)}\")\n",
        "print(f\"特徵列表前10個: {ALL_FEATURES[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pZiaiSJWnP8",
        "outputId": "dc6c8dc3-45aa-453f-b7cb-559a447cff53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[Part 1/6] 資料收集與特徵工程\n",
            "================================================================================\n",
            "下載 AAPL 資料：2020-01-01 至 2024-12-31\n",
            "原始資料形狀：(1257, 5)\n",
            "\n",
            "計算技術指標...\n",
            "總特徵數: 26\n",
            "特徵列表前10個: ['SMA_5', 'SMA_10', 'SMA_20', 'EMA_12', 'EMA_26', 'MACD', 'MACD_SIGNAL', 'MACD_HIST', 'RSI_14', 'STOCH_K']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 2/6] 資料分割與預處理\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_size = int(len(stock_data) * 0.7)\n",
        "val_size = int(len(stock_data) * 0.15)\n",
        "\n",
        "train_data = stock_data[:train_size]\n",
        "val_data = stock_data[train_size:train_size + val_size]\n",
        "test_data = stock_data[train_size + val_size:]\n",
        "\n",
        "X_train = train_data[ALL_FEATURES]\n",
        "y_train = train_data['Target']\n",
        "X_val = val_data[ALL_FEATURES]\n",
        "y_val = val_data['Target']\n",
        "X_test = test_data[ALL_FEATURES]\n",
        "y_test = test_data['Target']\n",
        "\n",
        "print(f\"訓練集: {len(X_train)} 筆\")\n",
        "print(f\"驗證集: {len(X_val)} 筆\")\n",
        "print(f\"測試集: {len(X_test)} 筆\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "lookback_period = 10\n",
        "\n",
        "def create_sequences(X, y, lookback):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - lookback):\n",
        "        Xs.append(X[i:i+lookback])\n",
        "        ys.append(y[i+lookback])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, lookback_period)\n",
        "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, lookback_period)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test.values, lookback_period)\n",
        "\n",
        "print(f\"\\n時間序列形狀:\")\n",
        "print(f\"  訓練集: {X_train_seq.shape}\")\n",
        "print(f\"  驗證集: {X_val_seq.shape}\")\n",
        "print(f\"  測試集: {X_test_seq.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz4WYqt2XCce",
        "outputId": "61f55bae-a1d9-4965-9bc9-310223394539"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 2/6] 資料分割與預處理\n",
            "================================================================================\n",
            "訓練集: 852 筆\n",
            "驗證集: 182 筆\n",
            "測試集: 184 筆\n",
            "\n",
            "時間序列形狀:\n",
            "  訓練集: (842, 10, 26)\n",
            "  驗證集: (172, 10, 26)\n",
            "  測試集: (174, 10, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 3/6] 模型定義\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMRegressor(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.2, output_dim=1):\n",
        "\n",
        "\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers # Add this line to store num_layers as an instance attribute\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim//2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "print(\"LSTM模型定義完成\")\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=30, lr=1e-3, verbose=False):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    best_loss = float('inf')\n",
        "    patience, patience_counter = 10, 0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(Xb)\n",
        "            loss = criterion(out.squeeze(), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                Xb, yb = Xb.to(device), yb.to(device)\n",
        "                val_loss += criterion(model(Xb).squeeze(), yb).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                if verbose: print(f\"  Early stopping at epoch {ep+1}\")\n",
        "                break\n",
        "\n",
        "        if verbose and (ep+1) % 10 == 0:\n",
        "            print(f\"  Epoch {ep+1}/{epochs} - Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(torch.Tensor(X_test).to(device)).cpu().squeeze().numpy()\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    return rmse, mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6xviygxXRH6",
        "outputId": "88f27e50-2ad8-453a-ec2d-e0b2cdc78287"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 3/6] 模型定義\n",
            "================================================================================\n",
            "LSTM模型定義完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 4/6] 階段1 - Baseline (全特徵)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_loader_full = DataLoader(\n",
        "    TensorDataset(torch.Tensor(X_train_seq), torch.Tensor(y_train_seq)),\n",
        "    batch_size=32, shuffle=True\n",
        ")\n",
        "val_loader_full = DataLoader(\n",
        "    TensorDataset(torch.Tensor(X_val_seq), torch.Tensor(y_val_seq)),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "print(\"\\n訓練 LSTM-Baseline...\")\n",
        "trans_baseline = LSTMRegressor(len(ALL_FEATURES)).to(device)\n",
        "trans_baseline = train_model(trans_baseline, train_loader_full, val_loader_full, epochs=50, verbose=True)\n",
        "rmse_trans_base, mae_trans_base = evaluate_model(trans_baseline, X_test_seq, y_test_seq)\n",
        "print(f\"LSTM-Baseline RMSE: {rmse_trans_base:.6f}, MAE: {mae_trans_base:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT3a7bdRXm2l",
        "outputId": "aaa6f606-c97c-454f-c77b-a03faafb80ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 4/6] 階段1 - Baseline (全特徵)\n",
            "================================================================================\n",
            "\n",
            "訓練 LSTM-Baseline...\n",
            "  Epoch 10/50 - Val Loss: 1984.493103\n",
            "  Early stopping at epoch 17\n",
            "LSTM-Baseline RMSE: 85.477834, MAE: 83.061497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 特徵子集評估函數\n",
        "# ============================================================================\n",
        "def evaluate_feature_subset(features, model_class, n_trials=3, epochs=20, verbose=False):\n",
        "    \"\"\"\n",
        "    評估特定特徵子集的效能\n",
        "\n",
        "    【為什麼需要這個函數？】\n",
        "    這是GA和SA的核心評估函數（適應度函數）\n",
        "\n",
        "    【如何運作】\n",
        "    1. 接收一組特徵\n",
        "    2. 用這些特徵訓練模型\n",
        "    3. 在驗證集上評估\n",
        "    4. 返回RMSE（越小越好）\n",
        "\n",
        "    【為什麼要多次試驗（n_trials）？】\n",
        "    原因：神經網路訓練有隨機性\n",
        "    - 權重初始化是隨機的\n",
        "    - Dropout是隨機的\n",
        "    - 資料打亂是隨機的\n",
        "\n",
        "    解決方案：\n",
        "    - 訓練n_trials次，取平均\n",
        "    - 減少偶然性的影響\n",
        "    - 得到更可靠的評估\n",
        "\n",
        "    參數：\n",
        "    - features: 特徵名稱列表\n",
        "    - model_class: 模型類別（LSTMRegressor）\n",
        "    - n_trials: 評估次數（減少隨機性）\n",
        "    - epochs: 訓練輪數（不需要太多，因為只是評估）\n",
        "    - verbose: 是否顯示詳細資訊\n",
        "\n",
        "    返回：\n",
        "    - mean_rmse: 平均RMSE\n",
        "    - std_rmse: RMSE的標準差（衡量穩定性）\n",
        "    \"\"\"\n",
        "    # 為什麼至少要有一個特徵 --> 沒有特徵無法訓練模型\n",
        "    if len(features) == 0:\n",
        "        return np.inf, 0 # 返回無窮大，表示這是糟糕的解\n",
        "\n",
        "    # ========================================\n",
        "    # 提取選中的特徵\n",
        "    # ========================================\n",
        "    # 根據特徵名稱找到對應的列索引\n",
        "    f_idx = [ALL_FEATURES.index(f) for f in features]\n",
        "    Xtr = X_train_scaled[:, f_idx]\n",
        "    Xva = X_val_scaled[:, f_idx]\n",
        "    # 創建時間序列\n",
        "    Xtr_seq, ytr_seq = create_sequences(Xtr, y_train.values, lookback_period)\n",
        "    Xva_seq, yva_seq = create_sequences(Xva, y_val.values, lookback_period)\n",
        "    # 創建DataLoader\n",
        "    tr_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xtr_seq), torch.Tensor(ytr_seq)),\n",
        "        batch_size=32, shuffle=True\n",
        "    )\n",
        "    va_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xva_seq), torch.Tensor(yva_seq)),\n",
        "        batch_size=32\n",
        "    )\n",
        "    # 多次試驗\n",
        "    scores = []\n",
        "    for trial in range(n_trials):\n",
        "        # 設定不同的隨機種子\n",
        "        # 為什麼？確保每次試驗的初始化不同，但整體可重現\n",
        "        torch.manual_seed(SEED + trial)\n",
        "        np.random.seed(SEED + trial)\n",
        "        # 創建並訓練模型\n",
        "        model = model_class(len(features)).to(device)\n",
        "        model = train_model(model, tr_loader, va_loader, epochs=epochs, verbose=False)\n",
        "        # 評估\n",
        "        rmse, _ = evaluate_model(model, Xva_seq, yva_seq)\n",
        "        scores.append(rmse)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    Trial {trial+1}/{n_trials}: RMSE = {rmse:.6f}\")\n",
        "\n",
        "    mean_rmse = np.mean(scores)\n",
        "    std_rmse = np.std(scores)\n",
        "\n",
        "    return mean_rmse, std_rmse\n",
        "\n",
        "# ============================================================================\n",
        "# 修改區域：實驗參數設定\n",
        "# ============================================================================\n",
        "#\n",
        "# 作業說明：\n",
        "# 請修改以下參數，進行不同的實驗，觀察參數如何影響結果\n",
        "#\n",
        "# 實驗建議：\n",
        "# 1. 固定其他參數，只改變一個參數（例如：世代數）\n",
        "# 2. 記錄每組實驗的結果（RMSE、特徵數、運行時間）\n",
        "# 3. 分析參數對結果的影響\n",
        "#\n",
        "# ============================================================================\n",
        "\n",
        "# --------------------------------------------\n",
        "# 基因演算法 (GA) 參數\n",
        "# --------------------------------------------\n",
        "# TODO: 修改以下參數進行實驗\n",
        "\n",
        "ga_generations = 8         # 世代數（建議範圍: 10-25）\n",
        "                            # 越多：收斂越好，但時間越長\n",
        "                            # 越少：速度快，但可能收斂不足\n",
        "                            # 建議：先用10試試，如果結果還在改善就增加\n",
        "\n",
        "ga_pop_size = 20           # 族群大小（建議範圍: 15-30）\n",
        "                           # 越大：搜索空間大，多樣性好，不易早熟\n",
        "                           # 越小：速度快，但容易困在局部最優\n",
        "                           # 建議：特徵數越多，族群就要越大\n",
        "\n",
        "ga_mutation_rate = 0.15    # 變異率（建議範圍: 0.1-0.25）\n",
        "                           # 越高：探索性強，多樣性好，但不穩定\n",
        "                           # 越低：收斂快，但可能困在局部最優\n",
        "\n",
        "# --------------------------------------------\n",
        "# 模擬退火 (SA) 參數\n",
        "# --------------------------------------------\n",
        "# TODO: 修改以下參數進行實驗\n",
        "\n",
        "sa_T_init = 50             # 初始溫度（建議範圍: 30-100）\n",
        "                           # 越高：接受劣解機率大，探索性強\n",
        "                           # 越低：較快收斂到局部最優\n",
        "\n",
        "sa_cooling_rate = 0.85     # 冷卻率（建議範圍: 0.80-0.95）\n",
        "                           # 越高：降溫慢，搜索細緻，但時間長\n",
        "                           # 越低：降溫快，收斂快但可能不夠好\n",
        "\n",
        "sa_T_min = 1               # 最低溫度（建議保持在1）\n",
        "                      # 溫度降到這個值就停止\n",
        "\n",
        "# --------------------------------------------\n",
        "# 通用參數\n",
        "# --------------------------------------------\n",
        "n_trials = 3               # 每個特徵組合評估次數（建議保持在3）\n",
        "                      # 用於減少隨機性影響\n",
        "                      # 太多會很慢，太少結果不穩定\n",
        "\n",
        "epochs_inner = 40          # GA/SA內部評估時的訓練輪數\n",
        "\n",
        "\n",
        "epochs_final = 50          # 最終測試集評估的訓練輪數\n",
        "                     # 與baseline保持一致\n",
        "\n",
        "# ============================================================================\n",
        "# 修改區域結束\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"實驗參數設定\")\n",
        "print(\"=\"*80)\n",
        "print(f\"GA參數: 世代數={ga_generations}, 族群大小={ga_pop_size}, 變異率={ga_mutation_rate}\")\n",
        "print(f\"SA參數: 初始溫度={sa_T_init}, 冷卻率={sa_cooling_rate}\")\n",
        "print(f\"評估參數: 每個組合評估{n_trials}次, 內部訓練{epochs_inner}輪\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# [Part 5/6] 階段2 & 3 - 基因演算法 & 模擬退火\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 5/6] 階段2 & 3 - 進化演算法特徵篩選\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========================================\n",
        "# 基因演算法\n",
        "# ========================================\n",
        "def genetic_algorithm(model_class, model_name, generations, pop_size,\n",
        "                     mutation_rate, n_trials, verbose=True):\n",
        "    \"\"\"基因演算法特徵選擇\"\"\"\n",
        "    \"\"\"\n",
        "    基因演算法特徵選擇\n",
        "\n",
        "    【演算法靈感】\n",
        "    模擬生物進化過程：\n",
        "    1. 自然選擇：適者生存\n",
        "    2. 基因交叉：父母特徵混合產生後代\n",
        "    3. 突變：隨機變異保持多樣性\n",
        "\n",
        "    【如何運作】\n",
        "\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 1. 初始化族群                                 │\n",
        "    │    隨機生成pop_size個染色體                         │\n",
        "    │    每個染色體 = [1,0,1,0,...]（特徵選擇）                 │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 2. 評估適應度                                 │\n",
        "    │    對每個個體訓練模型，計算RMSE                       │\n",
        "    │    RMSE越小 = 適應度越高\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 3. 選擇（Selection）                              │\n",
        "    │    保留表現最好的一半個體作為父母                      │\n",
        "    │    淘汰表現差的個體                             │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 4. 交叉（Crossover）                              │\n",
        "    │    隨機配對兩個父母                             │\n",
        "    │    在隨機位置切割染色體                           │\n",
        "    │    前半來自父親，後半來自母親                        │\n",
        "    │                                         │\n",
        "    │    父親: [1,1,0,0,1,1]                           │\n",
        "    │    母親: [0,1,1,1,0,0]                           │\n",
        "    │         切割點↑                            │\n",
        "    │    後代: [1,1,0|1,0,0]                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 5. 突變（Mutation）                              │\n",
        "    │    以mutation_rate的機率翻轉每個基因\n",
        "    │    [1,1,0,1,0,0] → [1,0,0,1,0,0]                     │\n",
        "    │           ↑翻轉                           │\n",
        "    │    目的：避免早熟收斂、保持多樣性                      │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 6. 重複2-5直到達到世代數                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "\n",
        "    【為什麼有效】\n",
        "    - 好的特徵組合會被保留和傳播\n",
        "    - 壞的特徵組合會被淘汰\n",
        "    - 交叉和突變產生新的組合\n",
        "    - 經過多代進化，族群整體越來越好\n",
        "\n",
        "    參數：\n",
        "    - model_class: 模型類別\n",
        "    - model_name: 模型名稱（用於顯示）\n",
        "    - generations: 進化世代數\n",
        "    - pop_size: 族群大小\n",
        "    - mutation_rate: 變異率\n",
        "    - n_trials: 評估時的試驗次數\n",
        "    - verbose: 是否顯示詳細過程\n",
        "\n",
        "    返回：\n",
        "    - best_features: 最佳特徵列表\n",
        "    - history: 進化歷史記錄\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"基因演算法 - {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"參數設定: 世代數={generations}, 族群大小={pop_size}, 變異率={mutation_rate}\")\n",
        "\n",
        "    # ========================================\n",
        "    # 1. 初始化族群\n",
        "    # ========================================\n",
        "    # 【染色體編碼】\n",
        "    # 每個個體是一個二進位陣列，長度 = 特徵數\n",
        "    # [1, 0, 1, 1, 0, ...] 表示選擇第1、3、4個特徵\n",
        "    #\n",
        "    # 為什麼用隨機初始化？\n",
        "    # - 保證多樣性\n",
        "    # - 覆蓋整個搜索空間\n",
        "\n",
        "    population = [np.random.choice([0, 1], len(ALL_FEATURES)) for _ in range(pop_size)]\n",
        "    # 記錄進化歷史\n",
        "    history = {\n",
        "        'best_scores': [], # 每代最佳分數\n",
        "        'mean_scores': [], # 每代平均分數\n",
        "        'worst_scores': [], # 每代最差分數\n",
        "        'best_features': [], # 每代最佳特徵組合\n",
        "        'best_n_features': [] # 每代最佳特徵數量\n",
        "    }\n",
        "\n",
        "    best_individual = None\n",
        "    best_score = float('inf')\n",
        "\n",
        "    # ========================================\n",
        "    # 2. 進化主循環\n",
        "    # ========================================\n",
        "    for gen in range(generations):\n",
        "        print(f\"\\n第 {gen+1}/{generations} 代:\")\n",
        "\n",
        "        # ========================================\n",
        "        # 2.1 評估適應度\n",
        "        # ========================================\n",
        "        scored_population = []\n",
        "        for idx, individual in enumerate(population):\n",
        "            # 解碼：將染色體轉換為特徵列表\n",
        "            selected_features = [f for i, f in enumerate(ALL_FEATURES) if individual[i] == 1]\n",
        "            # 評估這組特徵的性能\n",
        "            if len(selected_features) == 0:\n",
        "                score = np.inf # 沒有特徵 = 最差\n",
        "                std = 0\n",
        "            else:\n",
        "                score, std = evaluate_feature_subset(selected_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "\n",
        "            scored_population.append((score, std, individual, selected_features))\n",
        "\n",
        "            if verbose and (idx + 1) % 5 == 0:\n",
        "                print(f\"  評估進度: {idx+1}/{pop_size} (當前RMSE: {score:.6f}±{std:.4f}, 特徵數: {len(selected_features)})\")\n",
        "        # 按分數排序\n",
        "        scored_population.sort(key=lambda x: x[0])\n",
        "\n",
        "        # ========================================\n",
        "        # 2.2 記錄統計資訊\n",
        "        # ========================================\n",
        "        scores = [s[0] for s in scored_population if s[0] != np.inf]\n",
        "        if len(scores) > 0:\n",
        "            history['best_scores'].append(scored_population[0][0])\n",
        "            history['mean_scores'].append(np.mean(scores))\n",
        "            history['worst_scores'].append(scored_population[-1][0])\n",
        "            history['best_features'].append(scored_population[0][3])\n",
        "            history['best_n_features'].append(len(scored_population[0][3]))\n",
        "\n",
        "            print(f\"  最佳RMSE: {scored_population[0][0]:.6f}±{scored_population[0][1]:.4f} (特徵數: {len(scored_population[0][3])})\")\n",
        "            print(f\"  平均RMSE: {np.mean(scores):.6f}\")\n",
        "            print(f\"  最差RMSE: {scored_population[-1][0]:.6f}\")\n",
        "        # 更新全局最佳\n",
        "        if scored_population[0][0] < best_score:\n",
        "            best_score = scored_population[0][0]\n",
        "            best_individual = scored_population[0][2].copy()\n",
        "            print(f\"  發現新的最佳解！RMSE = {best_score:.6f}\")\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        # 2.3 選擇（Selection）\n",
        "        # ========================================\n",
        "        # 【選擇策略】\n",
        "        # 1. 精英保留（Elitism）：直接保留最好的20%\n",
        "        #    - 確保好的解不會丟失\n",
        "        # 2. 剩餘80%由父母交叉產生\n",
        "        #    - 保持多樣性\n",
        "        n_parents = pop_size // 2 # 前50%作為父母\n",
        "        parents = [ind for _, _, ind, _ in scored_population[:n_parents]]\n",
        "\n",
        "        n_elite = pop_size // 5 # 保留前20%\n",
        "        new_population = [scored_population[i][2].copy() for i in range(n_elite)]\n",
        "\n",
        "        # ========================================\n",
        "        # 2.4 交叉（Crossover）+ 突變（Mutation）\n",
        "        # ========================================\n",
        "        while len(new_population) < pop_size:\n",
        "            # 隨機選擇兩個父母\n",
        "            parent1, parent2 = random.sample(parents, 2)\n",
        "            # ========================================\n",
        "            # 單點交叉（Single-Point Crossover）\n",
        "            # ========================================\n",
        "            # 【如何運作】\n",
        "            # 1. 隨機選擇切割點\n",
        "            # 2. 前半來自parent1，後半來自parent2\n",
        "            #\n",
        "            # 例如：\n",
        "            # parent1: [1, 1, 0, | 0, 1, 1]\n",
        "            # parent2: [0, 1, 1, | 1, 0, 0]\n",
        "            #            ↑ 切割點\n",
        "            # child:   [1, 1, 0, | 1, 0, 0]\n",
        "\n",
        "            crossover_point = random.randint(1, len(ALL_FEATURES) - 1)\n",
        "            child = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n",
        "            # ========================================\n",
        "            # 突變（Mutation）\n",
        "            # ========================================\n",
        "            # 【如何運作】\n",
        "            # 以mutation_rate的機率翻轉每個基因\n",
        "            #\n",
        "            # 【為什麼需要突變】\n",
        "            # 1. 保持多樣性\n",
        "            # 2. 避免早熟收斂（整個族群變得太相似）\n",
        "            # 3. 探索新的特徵組合\n",
        "            for i in range(len(child)):\n",
        "                if random.random() < mutation_rate:\n",
        "                    child[i] = 1 - child[i] # 0變1，1變0\n",
        "\n",
        "            new_population.append(child)\n",
        "        # 更新族群\n",
        "        population = new_population\n",
        "    # ========================================\n",
        "    # 3. 返回最佳解\n",
        "    # ========================================\n",
        "    best_features = [f for i, f in enumerate(ALL_FEATURES) if best_individual[i] == 1]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"基因演算法完成！\")\n",
        "    print(f\"最佳RMSE: {best_score:.6f}\")\n",
        "    print(f\"選出特徵數: {len(best_features)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_features, history\n",
        "\n",
        "# ========================================\n",
        "# 模擬退火\n",
        "# ========================================\n",
        "def simulated_annealing(model_class, model_name, T_init, cooling_rate,\n",
        "                       T_min, n_trials, verbose=True):\n",
        "    \"\"\"\n",
        "    模擬退火特徵選擇\n",
        "\n",
        "    【演算法靈感】\n",
        "    模擬金屬退火過程：\n",
        "    1. 高溫：原子活躍，可以移動到任何位置\n",
        "    2. 慢慢降溫：原子逐漸穩定\n",
        "    3. 低溫：原子固定在能量最低的位置\n",
        "\n",
        "    【如何運作】\n",
        "\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 1. 初始化                                   │\n",
        "    │    隨機選擇一組特徵                             │\n",
        "    │    設定初始溫度T = T_init                         │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 2. 產生鄰居解                                 │\n",
        "    │    隨機翻轉一個特徵的選擇狀態                        │\n",
        "    │    當前: [1,0,1,1,0]                            │\n",
        "    │    鄰居: [1,1,1,1,0]  ←第2個特徵翻轉                   │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 3. 計算適應度變化                               │\n",
        "    │    Δ = 鄰居的RMSE - 當前的RMSE                     │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "          ┌─────────┴─────────┐\n",
        "          │                   │\n",
        "       Δ < 0                  Δ ≥ 0\n",
        "       (變好)                     (變差)\n",
        "          │                   │\n",
        "          ↓                   ↓\n",
        "    ┌──────────┐      ┌──────────────────┐\n",
        "    │必定接受      │      │以機率P接受:            │\n",
        "    │          │      │P = exp(-Δ/T)          │\n",
        "    │          │      │                  │\n",
        "    │          │      │溫度高→P大→易接受         │\n",
        "    │          │      │溫度低→P小→難接受         │\n",
        "    └──────────┘      └──────────────────┘\n",
        "          │                   │\n",
        "          └─────────┬─────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 4. 降溫                                    │\n",
        "    │    T = T * cooling_rate                         │\n",
        "    │    (例如：T = T * 0.85)                         │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 5. 重複2-4直到T < T_min                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "\n",
        "    【核心機制：接受機率】\n",
        "\n",
        "    P(接受) = exp(-Δ/T)\n",
        "\n",
        "    當Δ=10（鄰居差10單位）：\n",
        "    - T=100: P=exp(-10/100)=0.90 → 很可能接受\n",
        "    - T=50:  P=exp(-10/50)=0.82  → 可能接受\n",
        "    - T=10:  P=exp(-10/10)=0.37  → 不太接受\n",
        "    - T=1:   P=exp(-10/1)=0.00   → 幾乎不接受\n",
        "\n",
        "    【為什麼有效】\n",
        "    1. 高溫階段：\n",
        "       - 大膽探索，接受劣解\n",
        "       - 跳出局部最優\n",
        "\n",
        "    2. 中溫階段：\n",
        "       - 謹慎探索\n",
        "       - 偶爾接受劣解\n",
        "\n",
        "    3. 低溫階段：\n",
        "       - 只接受好解\n",
        "       - 收斂到最優\n",
        "\n",
        "    【與GA的區別】\n",
        "    - GA：族群並行搜索（多個解同時進化）\n",
        "    - SA：單一解逐步改進（更節省記憶體）\n",
        "\n",
        "    參數：\n",
        "    - model_class: 模型類別\n",
        "    - model_name: 模型名稱\n",
        "    - T_init: 初始溫度（控制探索程度）\n",
        "    - cooling_rate: 冷卻率（控制降溫速度）\n",
        "    - T_min: 最低溫度（停止條件）\n",
        "    - n_trials: 評估時的試驗次數\n",
        "    - verbose: 是否顯示詳細過程\n",
        "\n",
        "    返回：\n",
        "    - best_features: 最佳特徵列表\n",
        "    - history: 搜索歷史記錄\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"模擬退火 - {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"參數設定: 初始溫度={T_init}, 冷卻率={cooling_rate}, 最低溫度={T_min}\")\n",
        "\n",
        "    # ========================================\n",
        "    # 1. 初始化\n",
        "    # ========================================\n",
        "    # 隨機生成初始解\n",
        "    current_solution = np.random.choice([0, 1], len(ALL_FEATURES))\n",
        "    current_features = [f for i, f in enumerate(ALL_FEATURES) if current_solution[i] == 1]\n",
        "    current_score, current_std = evaluate_feature_subset(current_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "    # 記錄全局最佳\n",
        "    best_solution = current_solution.copy()\n",
        "    best_score = current_score\n",
        "    best_features = current_features.copy()\n",
        "    # 記錄搜索歷史\n",
        "    history = {\n",
        "        'temperatures': [],# 溫度變化\n",
        "        'current_scores': [], # 當前解的分數\n",
        "        'best_scores': [], # 最佳解的分數\n",
        "        'n_features': [], # 特徵數量\n",
        "        'acceptance_count': 0, # 接受次數\n",
        "        'total_iterations': 0 # 總迭代次數\n",
        "    }\n",
        "\n",
        "    T = T_init\n",
        "    iteration = 0\n",
        "\n",
        "    print(f\"\\n初始解: RMSE = {current_score:.6f}±{current_std:.4f} (特徵數: {len(current_features)})\")\n",
        "\n",
        "    # ========================================\n",
        "    # 2. 退火主循環\n",
        "    # ========================================\n",
        "    while T > T_min:\n",
        "        iteration += 1\n",
        "        history['total_iterations'] = iteration\n",
        "\n",
        "        # ========================================\n",
        "        # 2.1 產生鄰居解\n",
        "        # ========================================\n",
        "        # 【鄰域定義】\n",
        "        # 翻轉一個特徵的選擇狀態\n",
        "        #\n",
        "        # 為什麼只翻轉一個？\n",
        "        # - 保證鄰居解與當前解相似\n",
        "        # - 逐步搜索，而非隨機跳躍\n",
        "\n",
        "        neighbor = current_solution.copy()\n",
        "        flip_idx = random.randint(0, len(ALL_FEATURES) - 1)\n",
        "        neighbor[flip_idx] = 1 - neighbor[flip_idx]\n",
        "        # 解碼鄰居\n",
        "        neighbor_features = [f for i, f in enumerate(ALL_FEATURES) if neighbor[i] == 1]\n",
        "        # 評估鄰居\n",
        "        if len(neighbor_features) == 0:\n",
        "            neighbor_score = np.inf\n",
        "            neighbor_std = 0\n",
        "        else:\n",
        "            neighbor_score, neighbor_std = evaluate_feature_subset(neighbor_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "\n",
        "        # ========================================\n",
        "        # 2.2 決定是否接受鄰居\n",
        "        # ========================================\n",
        "        delta = neighbor_score - current_score\n",
        "\n",
        "        if delta < 0:\n",
        "          # 鄰居更好 → 必定接受\n",
        "            accept = True\n",
        "        else:\n",
        "            # 鄰居更差 → 以機率接受\n",
        "            # 【Metropolis準則】\n",
        "            # P(接受) = exp(-Δ/T)\n",
        "            #\n",
        "            # 為什麼要接受劣解？\n",
        "            # 1. 跳出局部最優\n",
        "            # 2. 探索更多可能性\n",
        "            # 3. 溫度越高，接受機率越大\n",
        "            acceptance_prob = np.exp(-delta / T)\n",
        "            accept = random.random() < acceptance_prob\n",
        "        # 接受鄰居\n",
        "        if accept:\n",
        "            current_solution = neighbor\n",
        "            current_score = neighbor_score\n",
        "            current_std = neighbor_std\n",
        "            current_features = neighbor_features\n",
        "            history['acceptance_count'] += 1\n",
        "            # 更新全局最佳\n",
        "            if current_score < best_score:\n",
        "                best_score = current_score\n",
        "                best_solution = current_solution.copy()\n",
        "                best_features = current_features.copy()\n",
        "                print(f\"  迭代 {iteration}: 發現新的最佳解！RMSE = {best_score:.6f}±{current_std:.4f} (特徵數: {len(best_features)})\")\n",
        "        # ========================================\n",
        "        # 2.3 記錄歷史\n",
        "        # ========================================\n",
        "        history['temperatures'].append(T)\n",
        "        history['current_scores'].append(current_score)\n",
        "        history['best_scores'].append(best_score)\n",
        "        history['n_features'].append(len(current_features))\n",
        "\n",
        "        if verbose and iteration % 10 == 0:\n",
        "            acc_rate = history['acceptance_count'] / iteration * 100\n",
        "            print(f\"  迭代 {iteration}: T={T:.2f}, 當前RMSE={current_score:.6f}, \"\n",
        "                  f\"最佳RMSE={best_score:.6f}, 接受率={acc_rate:.1f}%\")\n",
        "        # ========================================\n",
        "        # 2.4 降溫\n",
        "        # ========================================\n",
        "        # 【冷卻策略：指數衰減】\n",
        "        # T = T * cooling_rate\n",
        "        #\n",
        "        # 例如：cooling_rate=0.85\n",
        "        # T = 100 → 85 → 72.25 → 61.41 → ...\n",
        "        #\n",
        "        # 為什麼用指數衰減？\n",
        "        # - 開始降溫慢（充分探索）\n",
        "        # - 後期降溫快（加速收斂）\n",
        "        T *= cooling_rate\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"模擬退火完成！\")\n",
        "    print(f\"總迭代次數: {iteration}\")\n",
        "    print(f\"接受率: {history['acceptance_count']/iteration*100:.1f}%\")\n",
        "    print(f\"最佳RMSE: {best_score:.6f}\")\n",
        "    print(f\"選出特徵數: {len(best_features)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_features, history\n",
        "\n",
        "# ========================================\n",
        "# 執行特徵篩選\n",
        "# ========================================\n",
        "print(\"\\n開始執行特徵篩選...\")\n",
        "\n",
        "# GA-LSTM\n",
        "ga_trans_features, ga_trans_history = genetic_algorithm(\n",
        "    LSTMRegressor, \"LSTM\",\n",
        "    generations=ga_generations,\n",
        "    pop_size=ga_pop_size,\n",
        "    mutation_rate=ga_mutation_rate,\n",
        "    n_trials=n_trials\n",
        ")\n",
        "\n",
        "# SA-LSTM\n",
        "sa_trans_features, sa_trans_history = simulated_annealing(\n",
        "    LSTMRegressor, \"LSTM\",\n",
        "    T_init=sa_T_init,\n",
        "    cooling_rate=sa_cooling_rate,\n",
        "    T_min=sa_T_min,\n",
        "    n_trials=n_trials\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LDeUoqgieAP2",
        "outputId": "ed7d43a1-bf50-49a5-d8fe-fcd69178598b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "實驗參數設定\n",
            "================================================================================\n",
            "GA參數: 世代數=8, 族群大小=20, 變異率=0.15\n",
            "SA參數: 初始溫度=50, 冷卻率=0.85\n",
            "評估參數: 每個組合評估3次, 內部訓練40輪\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "[Part 5/6] 階段2 & 3 - 進化演算法特徵篩選\n",
            "================================================================================\n",
            "\n",
            "開始執行特徵篩選...\n",
            "\n",
            "============================================================\n",
            "基因演算法 - LSTM\n",
            "============================================================\n",
            "參數設定: 世代數=8, 族群大小=20, 變異率=0.15\n",
            "\n",
            "第 1/8 代:\n",
            "  評估進度: 5/20 (當前RMSE: 33.388674±18.5395, 特徵數: 15)\n",
            "  評估進度: 10/20 (當前RMSE: 45.662364±0.2285, 特徵數: 12)\n",
            "  評估進度: 15/20 (當前RMSE: 21.923534±17.5343, 特徵數: 15)\n",
            "  評估進度: 20/20 (當前RMSE: 46.327331±0.5266, 特徵數: 9)\n",
            "  最佳RMSE: 8.230830±1.3568 (特徵數: 16)\n",
            "  平均RMSE: 33.678925\n",
            "  最差RMSE: 46.420904\n",
            "  發現新的最佳解！RMSE = 8.230830\n",
            "\n",
            "第 2/8 代:\n",
            "  評估進度: 5/20 (當前RMSE: 7.011951±0.5323, 特徵數: 14)\n",
            "  評估進度: 10/20 (當前RMSE: 22.247118±17.6134, 特徵數: 18)\n",
            "  評估進度: 15/20 (當前RMSE: 21.375093±17.2959, 特徵數: 13)\n",
            "  評估進度: 20/20 (當前RMSE: 9.781361±0.1757, 特徵數: 17)\n",
            "  最佳RMSE: 7.011951±0.5323 (特徵數: 14)\n",
            "  平均RMSE: 21.794752\n",
            "  最差RMSE: 46.200667\n",
            "  發現新的最佳解！RMSE = 7.011951\n",
            "\n",
            "第 3/8 代:\n",
            "  評估進度: 5/20 (當前RMSE: 8.729032±0.4243, 特徵數: 13)\n",
            "  評估進度: 10/20 (當前RMSE: 21.472322±17.3596, 特徵數: 14)\n",
            "  評估進度: 15/20 (當前RMSE: 9.003966±0.5463, 特徵數: 16)\n",
            "  評估進度: 20/20 (當前RMSE: 6.901218±0.3026, 特徵數: 13)\n",
            "  最佳RMSE: 6.901218±0.3026 (特徵數: 13)\n",
            "  平均RMSE: 17.580110\n",
            "  最差RMSE: 34.745955\n",
            "  發現新的最佳解！RMSE = 6.901218\n",
            "\n",
            "第 4/8 代:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2856138396.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;31m# GA-LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m ga_trans_features, ga_trans_history = genetic_algorithm(\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0mLSTMRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mga_generations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2856138396.py\u001b[0m in \u001b[0;36mgenetic_algorithm\u001b[0;34m(model_class, model_name, generations, pop_size, mutation_rate, n_trials, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_feature_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_inner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0mscored_population\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2856138396.py\u001b[0m in \u001b[0;36mevaluate_feature_subset\u001b[0;34m(features, model_class, n_trials, epochs, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# 創建並訓練模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;31m# 評估\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXva_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myva_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1635237204.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs, lr, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}